traces/load_imbalance:

This directory contains various trace files that are used to study scheduler load 
imbalance issues related to real-time group scheduling and cgroup-v1 cpu/cpuacct 
and cpuset controllers. All the traces here are generated using 
1.  tools/nprocs/cgroup.sh
2.  tools/nprocs/setpolicy.sh
3.  tools/launcher/lauch_cg_setpol.sh 
4.  tools/launcher/launch_cg_native.sh 

cgroup.sh:
    is a shell script that executes tools/nprocs/nprocs, traces it, and adds 
    the spawned processes to cpu and cpuset cgroup(s). It is used to study load 
    balancing, real-time group scheduling, and the "no-check" kernel in relation 
    to cgroup-v1.

setpolicy.sh 
    also executes tools/nprocs/nprocs. It simply launches it with a real-
    time priority with different means ("manual", i.e., by calls to 
    sched_setschedular() in the parent or children, v.s. using schedtool/launcher) 
    and traces it.

lauch_cg_setpol.sh:
    invokes the launcher program to execute cgroup.sh and setpolicy.sh

launch_cg_native.sh:
    configurates command-line arguments to launcher, which in turn executes the
    nprocs program with appropriate priority, core affinity, real-time group
    scheduling runtime/period, etc. Also performs tracing and clean-up. Generally 
    similar functionality as cgroup.sh



The three subdirectories are no_check_rt_group_uclamp, rt_group_uclamp, and uclamp.
The traces in these directories were collected refer to following kernels:

Linux muhanyupi 5.10.17-v7_no_check_rt_group_uclamp #12 SMP PREEMPT Thu Jul 6 00:52:03 CDT 2023 armv7l GNU/Linux
Linux muhanyupi 5.10.17-v7_rt_group_uclamp #14 SMP PREEMPT Thu Jul 6 02:11:41 CDT 2023 armv7l GNU/Linux
Linux muhanyupi 5.10.17-v7_uclamp #17 SMP PREEMPT Thu Jul 6 03:20:34 CDT 2023 armv7l GNU/Linux



Each subdirectory further contains three subdirectories: sudo_bash, high_prio_bash, 
launch, and launch_native:

sudo_bash:          
    cgroup.sh and setpolicy.sh are invoked in a regular sudo session

high_prio_bash:     
    cgroup.sh and setpolicy.sh are launched in a sudo bash session with static
    priority of 91, using "chrt -p 91 <pid>". E.g.:

    pi@muhanyupi:~/research/tools/schedtool $ sudo chrt -p 99 8097
    pi@muhanyupi:~/research/tools/schedtool $ ./schedtool 8097
    PID  8097: PRIO  91, POLICY R: SCHED_RR      , NICE   0, AFFINITY 0xf

launch_cg_setpol:           
    cgroup.sh and setpolicy.sh are launched by tools/launcher/launch_cg_setpol.sh,
    which itself is launched in a sudo bash shell.



Under the aforementioned four subdirectory contain the trace files. There are 
two kinds of trace files:

#1: cg.<set policy>.<policy>.<# of processes>.<# of cgroups>.<# of cpus per cgroup>.disjnt_cpuset.<rt_runtime_us>.<interval time>s.*.dat

These trace files are generated by cgroup.sh and launch_native.sh

1. <set policy>:        how RT policy was set:
                        0 -> by tools/schedtool/schedtool
                        1 -> by tools/launcher/launcher
                        2 -> call sched_setschedular() in parent before fork
                        3 -> call sched_setschedular() in children

2. <policy>:            real-time scheduling policy:
                        F -> SCHED_FIFO
                        R -> SCHED_RR

3. <# of processes>
4. <# of cgroups>
5. <# of cpus per cgroup>
6. disjnt_cpuset:       refers to the fact that each cpuset cgroup is assigned
                        one or two cpu(s) uniquely (although they do NOT have 
                        exlusive access to the said cpus, i.e. cpuset.cpu_exclusive 
                        flag is NOT set).

7. <rt_runtime_us>:     refers to the cgroup-v1 cpu controller interface 
                        file cpu.rt_runtime_us. For the normal rt-group 
                        scheduling kernel, the sum of cpu.rt_runtime_us
                        divided by cpu.rt_period_us for sibling cgroups 
                        cannot be larger than what is available to the 
                        parent. For the "no-check" kernel this limitation
                        is removed.

8. <interval time>:     how long each phase in tracing process is, in seconds.


#2: setpo.<set policy>.<policy>.<# of processes>.<trace time>.*.dat

These trace files are generated by setpolicy.sh

1. <set policy>:        how RT policy was set:
                        0 -> by tools/schedtool/schedtool
                        1 -> by tools/launcher/launcher
                        2 -> call sched_setschedular() in parent before fork
                        3 -> call sched_setschedular() in children

2. <policy>:            real-time scheduling policy:
                        F -> SCHED_FIFO
                        R -> SCHED_RR

3. <# of processes>
4. <trace time>:        how long the tracing lasted, in seconds.


Examples:

traces/load_imbalance/uclamp/high_prio_bash/cg.1m.R.8p.2cg.2cpupcg.disjnt_cpuset.300000us.1.dat

A trace file generated by tools/nprocs/cgroup.sh, which itself is invoked in 
a 99 static priority sudo bash shell on a "uclamp" kernel. The processes 
obtained SCHED_RR policy from their parent's call to sched_setschedular() before 
fork(). Eight processes were spawned in total, and placed in two cgroup-v1 cpu
and cpuset cgroups. The cpu cgroup has a real-time runtime of 300000 
microseconds, while the cpuset cgroups each have assigned cpus. This is the first
trace file of (possibly) many files with the same parameters.
