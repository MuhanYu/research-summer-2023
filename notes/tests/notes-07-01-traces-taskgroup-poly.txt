Notes on trace files generated using the "no-check" kernel with cgroup v1
real-time group scheduling enabled. 

Using the "nprocs" program:

1.  The use of the schedtool program to launch the processes causes a problem
    when there are 8 procs, 2 cgroups, and 2 cpus per cgroup. 
    
    If schedtool is envoked with SCHED_RR policy, then time-sharing among the 
    eight processes is not correct. Some processes will run for a lot longer 
    than others. This is true both before and after the tasks are placed into
    cgroups.
    
    When using "./nprocs 7" to investigate this behavior (no cgroups), it could 
    be seen that the first three nprocs processes were granted exclusive access 
    to the first three cpus, while the rest of the five processes have the share 
    the last cpu.

    This problem can be replicated if sched_setscheduler() is called in the parent 
    before fork(). This problem is NOT due to the "reset-on-fork" scheduling flag; 
    each child indeed have SCHED_RR policy (see below):

    ---------------------------------------------------------------------------------------------------------
    # compiling with sched_setschedular() before fork()ing children
    pi@muhanyupi:~/research/tools/nprocs $ gcc -o nprocs -DPMANUAL nprocs.c
    pi@muhanyupi:~/research/tools/nprocs $ ./nprocs.c 7
    bash: ./nprocs.c: Permission denied
    pi@muhanyupi:~/research/tools/nprocs $ ./nprocs 7
    pid: 13050
    pid: 13049
    pid: 13051
    pid: 13048
    pid: 13052
    pid: 13053
    pid: 13054
    pid: 13055
    ^C
    pi@muhanyupi:~/research/tools/nprocs $ 

    # check scheduling policy (using schedtool leads to the same result)
    [root@muhanyupi /home/pi/research/tools/nprocs] # ps -e -o s,pid | grep ^R | awk '{system("chrt -p " $2)}'
    pid 12608's current scheduling policy: SCHED_OTHER
    pid 12608's current scheduling priority: 0
    pid 13048's current scheduling policy: SCHED_RR
    pid 13048's current scheduling priority: 90
    pid 13049's current scheduling policy: SCHED_RR
    pid 13049's current scheduling priority: 90
    pid 13050's current scheduling policy: SCHED_RR
    pid 13050's current scheduling priority: 90
    pid 13051's current scheduling policy: SCHED_RR
    pid 13051's current scheduling priority: 90
    pid 13052's current scheduling policy: SCHED_RR
    pid 13052's current scheduling priority: 90
    pid 13053's current scheduling policy: SCHED_RR
    pid 13053's current scheduling priority: 90
    pid 13054's current scheduling policy: SCHED_RR
    pid 13054's current scheduling priority: 90
    pid 13055's current scheduling policy: SCHED_RR
    pid 13055's current scheduling priority: 90
    chrt: failed to get pid 13123's policy: No such process
    chrt: failed to get pid 13124's policy: No such process
    ---------------------------------------------------------------------------------------------------------

    If the scheduling policy is instead changed with sched_setscheduler() in the
    child processes after fork(), then everything is fine. The time sharing between 
    SCHED_RR tasks are correct before and after being added to the two cgroups.

    HOWEVER, even though 

    It is unclear why this is the case. 

    ******************************************************************************
    SIDENOTE: when using 8 procs, 1 cgroup, and 1 cpu per cgroup, we see that 
    time sharing among 8 processes is the same regardless how the scheduling
    policies were manipulated. The runtime is divided evenly across 8 processes.

2.  When there are 8 procs, 2 cgroups, and 2 cpus per cgroup, the vanila run.sh 
    cannot be used to effectively study the behavior of FIFO processes and their
    interactions with cgroups. Since there are only 4 cpus, only 4 processes will 
    run initialially and write their pids to "procs_temp.txt". Therefore only these 
    4 processes will be added to the cgroup. Only after the 4 initial processes were
    added to the cgroup, the 4 remaining processes that did not get to run in the
    first place will have a chance to run, thereby writing their pids into
    "procs_temp.txt". 

    We can instead use a modified version run_fifo.sh, which checks exactly how many
    processes are the the cgroups right now, using the "tasks" file. The script only 
    stop adding more processes when the combined number of procs in those tasks files
    is the same as the the number of processes initially spawned. The only downside
    of this method is that it must repeatedly check those files. Also, different procs
    might be added to their cgroups at very different times.


Using Prof. Sudvarg's program:

1.  

